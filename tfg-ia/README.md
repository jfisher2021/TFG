# TFG-IA: EvaluaciÃ³n de LLMs para PlanificaciÃ³n PDDL

Este proyecto evalÃºa la capacidad de distintos modelos de lenguaje (LLMs) para generar planes PDDL vÃ¡lidos en un entorno de robot guÃ­a de museo, considerando restricciones de baterÃ­a y optimizaciÃ³n de rutas.

## ğŸŒ³ Ãrbol del Proyecto

```
tfg-ia/
â”‚
â”‚
â”œâ”€â”€ ğŸ¤– tfg_langchain/                    # ImplementaciÃ³n con LangChain/LangGraph
â”‚   â”œâ”€â”€ get_plan.py                      # â­ Script principal con StateGraph
â”‚   â””â”€â”€ scripts_evaluacion/
â”‚       â”œâ”€â”€ chat_flujo_completo.py       # Flujo completo + validaciÃ³n
â”‚       â”œâ”€â”€ return_goal_tool_genai.py    # Goals con Google GenAI
â”‚       â””â”€â”€ return_goal_tools_langchain.py
â”‚
â”œâ”€â”€ ğŸ¦™ tfg_ollama/                       # ImplementaciÃ³n con Ollama (local)
â”‚   â”œâ”€â”€ create_plan.py                   # â­ Script principal Ollama
â”‚   â”œâ”€â”€ logs/                            # Logs JSON/TXT de ejecuciones
â”‚   â”‚   â”œâ”€â”€ log.json
â”‚   â”‚   â”œâ”€â”€ log.txt
â”‚   â”‚   â””â”€â”€ logv2.txt
â”‚   â””â”€â”€ scripts_evaluacion/
â”‚       â”œâ”€â”€ doble_modelo_correccion.py   # Sistema generador + validador
â”‚       â””â”€â”€ validator.py                 # ValidaciÃ³n de planes PDDL
â”‚
â”œâ”€â”€ ğŸ¯ pddl/                             # Definiciones PDDL
â”‚   â”œâ”€â”€ domain.pddl                      # Dominio: acciones, predicados, funciones
â”‚   â””â”€â”€ problem.pddl                     # Problema: estado inicial y objetivos
â”‚
â”œâ”€â”€ ğŸ› ï¸ scripts/                          # Scripts auxiliares
â”‚   â”œâ”€â”€ create_explain_files.py          # Genera explicaciones con LLMs
â”‚   â”œâ”€â”€ run_chat_10_times.sh             # Pruebas repetitivas
â”‚   â””â”€â”€ analisis_experimentos.py         # AnÃ¡lisis : mÃ©tricas por modelo
â”‚
â”œâ”€â”€ ğŸ“ LOGS
â”‚   â”œâ”€â”€ log.txt / log.json               # Logs generales
â”‚   â”œâ”€â”€ log_gpt.txt                      # Logs especÃ­ficos GPT
â”‚   â””â”€â”€ logs_script*.txt                 # Logs de scripts especÃ­ficos
â”‚
â”œâ”€â”€ experimentos_pddl.csv            # Resultados de pruebas simples
â”œâ”€â”€ cuadros.csv                      # BD de cuadros 
â”œâ”€â”€ goals.txt                        # Objetivos de prueba en formato PDDL
â”œâ”€â”€ prompts.py                       # Todos los prompts del proyecto
â”œâ”€â”€ utils.py                         # Funciones auxiliares (logs, selecciÃ³n)
â”œâ”€â”€ pyproject.toml                   # Dependencias Python 3.13+
â”œâ”€â”€ ğŸ“„ conclusiones.md                   # Conclusiones del TFG
â””â”€â”€ README.md                            # Este archivo
```

## ğŸ“ Estructura del Proyecto

### ğŸ¯ Archivos Principales de EvaluaciÃ³n

#### Datos de Experimentos
- **`experimentos_pddl.csv`** - Resultados de pruebas individuales (formato simple)
- **`cuadros.csv`** - Base de datos de cuadros del museo (nombre, autor, estilo, paÃ­s, etc.)
- **`goals.txt`** - Archivo con diferentes objetivos de prueba en formato PDDL

#### ConfiguraciÃ³n y Utilidades
- **`prompts.py`** â­ - **IMPORTANTE**: Contiene todos los prompts usados para generar y validar planes
- **`utils.py`** - Funciones auxiliares (logging, selecciÃ³n de modelos, etc.)
- **`pyproject.toml`** - Dependencias del proyecto (Python 3.13+)

### ğŸ¤– Directorios de ImplementaciÃ³n

#### `tfg_langchain/`
ImplementaciÃ³n usando LangChain + LangGraph con modelos de OpenAI y Google GenAI
- **`get_plan.py`** â­ - Script principal que genera planes usando un grafo de estados (StateGraph)
  - Usa herramientas (tools) para consultar CSV cuando el goal es en lenguaje natural
- **`scripts_evaluacion/`**
  - `chat_flujo_completo.py` - Flujo completo con validaciÃ³n automÃ¡tica
  - `return_goal_tool_genai.py` - Procesamiento de goals con Google GenAI
  - `return_goal_tools_langchain.py` - Procesamiento de goals con LangChain

#### `tfg_ollama/`
ImplementaciÃ³n usando Ollama (modelos open-source locales)
- **`create_plan.py`** â­ - Script principal para generar planes con Ollama
  - Modelos probados: Llama, Deepseek, Minimax, etc.
- **`logs/`** - Logs de ejecuciÃ³n en JSON y TXT
- **`scripts_evaluacion/`**
  - `doble_modelo_correccion.py` â­ - Sistema de doble modelo (generador + validador)
  - `validator.py` - ValidaciÃ³n de planes PDDL

#### `pddl/`
Definiciones PDDL del dominio y problema
- **`domain.pddl`** - Dominio PDDL del robot guÃ­a (acciones, predicados, funciones)
- **`problem.pddl`** - Problema PDDL con estado inicial y objetivos

#### `scripts/`
Scripts auxiliares de utilidad
- `create_explain_files.py` - Genera explicaciones de cuadros usando LLMs
- `run_chat_10_times.sh` - Script de pruebas repetitivas
- **`analisis_experimentos.py`** - Analizador principal de resultados (v1). Lee `experimentos_pddl.csv` y genera mÃ©tricas por modelo

### ğŸ“ Archivos de Logs (Experimentales)
- `log.txt`, `log.json`, `log_gpt.txt` - Logs de ejecuciones de pruebas
- `logs_script.txt`, `logs_script_deepseek_razonamiento.txt` - Logs de scripts especÃ­ficos
- `colclusiones.md` - Documento con conclusiones del TFG

## ğŸš€ Uso RÃ¡pido

### Generar un plan con LangChain (Gemini/GPT)
```bash
python tfg_langchain/get_plan.py "Explica los cuadros espaÃ±oles"
```

### Generar un plan con Ollama
```bash
python tfg_ollama/create_plan.py "visited monalisa y explicar guernica"
```

### Evaluar con doble modelo (generador + validador)
```bash
python tfg_ollama/scripts_evaluacion/doble_modelo_correccion.py
```

### Analizar resultados
```bash
# AnÃ¡lisis simple
python analisis_experimentos.py

# AnÃ¡lisis con mÃ©tricas de planner/validator
python analisis_experimentos_v2.py
```

## ğŸ“Š Modelos Evaluados

- **OpenAI**: GPT-4o, GPT-4o-mini, GPT-o1-mini
- **Google**: Gemini 2.5 Pro, Gemini 2.5 Flash
- **Deepseek**: Deepseek-chat, Deepseek-r1
- **Meta**: Llama 3.x, Llama 4 Maverick
- **Groq**: Varios modelos optimizados para inferencia
- **Minimax**: M2 (MoE 230B/10B con razonamiento)
- **Otros**: Qwen, Mistral, Phi, etc.

## ğŸ”‘ Prompts Principales

Ver `prompts.py` para los prompts completos:
- `prompt_inicial_sin_ejemplos` - GeneraciÃ³n de planes (sin ejemplos)
- `prompt_con_3_ejemplos_input_goal` - GeneraciÃ³n con few-shot learning
- `validate_plan_prompt` - ValidaciÃ³n de planes en formato CSV
- `prompt_get_goal_con_csv` - ExtracciÃ³n de goals con consulta a base de datos

## ğŸ“¦ Dependencias

```bash
pip install -e .
```

Requiere: langchain, langgraph, ollama, pandas, google-genai, groq, openai

# TFG-IA: EvaluaciÃ³n de LLMs para PlanificaciÃ³n PDDL

Este proyecto evalÃºa la capacidad de distintos modelos de lenguaje (LLMs) para generar planes PDDL vÃ¡lidos en un entorno de robot guÃ­a de museo, considerando restricciones de baterÃ­a y optimizaciÃ³n de rutas.

## ğŸŒ³ Ãrbol del Proyecto

```
tfg-ia/
â”‚
â”œâ”€â”€ ğŸ“Š ANÃLISIS Y RESULTADOS
â”‚   â”œâ”€â”€ analisis_experimentos.py         # AnÃ¡lisis v1: mÃ©tricas por modelo
â”‚   â”œâ”€â”€ analisis_experimentos_v2.py      # AnÃ¡lisis v2: mÃ©tricas planner+validator
â”‚   â”œâ”€â”€ experimentos_pddl.csv            # Resultados de pruebas simples
â”‚   â””â”€â”€ experimentos_pddl_v2.csv         # Resultados con doble modelo
â”‚
â”œâ”€â”€ ğŸ“š DATOS Y CONFIGURACIÃ“N
â”‚   â”œâ”€â”€ cuadros.csv                      # BD de cuadros (nombre, autor, estilo, paÃ­s)
â”‚   â”œâ”€â”€ goals.txt                        # Objetivos de prueba en formato PDDL
â”‚   â”œâ”€â”€ prompts.py                       # â­ Todos los prompts del proyecto
â”‚   â”œâ”€â”€ utils.py                         # Funciones auxiliares (logs, selecciÃ³n)
â”‚   â””â”€â”€ pyproject.toml                   # Dependencias Python 3.13+
â”‚
â”œâ”€â”€ ğŸ¤– tfg_langchain/                    # ImplementaciÃ³n con LangChain/LangGraph
â”‚   â”œâ”€â”€ get_plan.py                      # â­ Script principal con StateGraph
â”‚   â””â”€â”€ scripts_evaluacion/
â”‚       â”œâ”€â”€ chat_flujo_completo.py       # Flujo completo + validaciÃ³n
â”‚       â”œâ”€â”€ return_goal_tool_genai.py    # Goals con Google GenAI
â”‚       â””â”€â”€ return_goal_tools_langchain.py
â”‚
â”œâ”€â”€ ğŸ¦™ tfg_ollama/                       # ImplementaciÃ³n con Ollama (local)
â”‚   â”œâ”€â”€ create_plan.py                   # â­ Script principal Ollama
â”‚   â”œâ”€â”€ logs/                            # Logs JSON/TXT de ejecuciones
â”‚   â”‚   â”œâ”€â”€ log.json
â”‚   â”‚   â”œâ”€â”€ log.txt
â”‚   â”‚   â””â”€â”€ logv2.txt
â”‚   â””â”€â”€ scripts_evaluacion/
â”‚       â”œâ”€â”€ doble_modelo_correccion.py   # â­ Sistema generador + validador
â”‚       â”œâ”€â”€ validator.py                 # ValidaciÃ³n de planes PDDL
â”‚       â”œâ”€â”€ get_goal_from_csv.py         # ExtracciÃ³n de goals desde CSV
â”‚       â”œâ”€â”€ plan_pruebas.py              # Suite de pruebas automatizadas
â”‚       â”œâ”€â”€ cuadros.ipynb                # Notebook anÃ¡lisis cuadros
â”‚       â””â”€â”€ logs/
â”‚
â”œâ”€â”€ ğŸ¯ pddl/                             # Definiciones PDDL
â”‚   â”œâ”€â”€ domain.pddl                      # Dominio: acciones, predicados, funciones
â”‚   â””â”€â”€ problem.pddl                     # Problema: estado inicial y objetivos
â”‚
â”œâ”€â”€ ğŸ› ï¸ scripts/                          # Scripts auxiliares
â”‚   â”œâ”€â”€ create_explain_files.py          # Genera explicaciones con LLMs
â”‚   â”œâ”€â”€ split_log_gpt.py                 # Procesa logs de GPT
â”‚   â”œâ”€â”€ trim_plans.py                    # Limpia y formatea planes
â”‚   â”œâ”€â”€ validate.bash                    # ValidaciÃ³n con VAL validator
â”‚   â”œâ”€â”€ run_chat_10_times.sh             # Pruebas repetitivas
â”‚   â””â”€â”€ re_practice.py                   # Experimentos regex
â”‚
â”œâ”€â”€ ğŸ“ LOGS (Experimentales)
â”‚   â”œâ”€â”€ log.txt / log.json               # Logs generales
â”‚   â”œâ”€â”€ log_gpt.txt                      # Logs especÃ­ficos GPT
â”‚   â””â”€â”€ logs_script*.txt                 # Logs de scripts especÃ­ficos
â”‚
â”œâ”€â”€ ğŸ“„ colclusiones.md                   # Conclusiones del TFG
â””â”€â”€ README.md                            # Este archivo
```

## ğŸ“ Estructura del Proyecto

### ğŸ¯ Archivos Principales de EvaluaciÃ³n

#### AnÃ¡lisis de Resultados
- **`analisis_experimentos.py`** - Analizador principal de resultados (v1). Lee `experimentos_pddl.csv` y genera mÃ©tricas por modelo
- **`analisis_experimentos_v2.py`** - Analizador avanzado (v2). Lee `experimentos_pddl_v2.csv` con mÃ©tricas por pareja planner/validator

#### Datos de Experimentos
- **`experimentos_pddl.csv`** - Resultados de pruebas individuales (formato simple)
- **`experimentos_pddl_v2.csv`** - Resultados con sistema de doble modelo (planner + validator)
- **`cuadros.csv`** - Base de datos de cuadros del museo (nombre, autor, estilo, paÃ­s, etc.)
- **`goals.txt`** - Archivo con diferentes objetivos de prueba en formato PDDL

#### ConfiguraciÃ³n y Utilidades
- **`prompts.py`** â­ - **IMPORTANTE**: Contiene todos los prompts usados para generar y validar planes
- **`utils.py`** - Funciones auxiliares (logging, selecciÃ³n de modelos, etc.)
- **`pyproject.toml`** - Dependencias del proyecto (Python 3.13+)

### ğŸ¤– Directorios de ImplementaciÃ³n

#### `tfg_langchain/`
ImplementaciÃ³n usando LangChain + LangGraph con modelos de OpenAI y Google GenAI
- **`get_plan.py`** â­ - Script principal que genera planes usando un grafo de estados (StateGraph)
  - Usa herramientas (tools) para consultar CSV cuando el goal es en lenguaje natural
  - Soporta: GPT-4, Gemini, Groq
- **`scripts_evaluacion/`**
  - `chat_flujo_completo.py` - Flujo completo con validaciÃ³n automÃ¡tica
  - `return_goal_tool_genai.py` - Procesamiento de goals con Google GenAI
  - `return_goal_tools_langchain.py` - Procesamiento de goals con LangChain

#### `tfg_ollama/`
ImplementaciÃ³n usando Ollama (modelos open-source locales)
- **`create_plan.py`** â­ - Script principal para generar planes con Ollama
  - Modelos probados: Llama, Deepseek, Minimax, etc.
- **`logs/`** - Logs de ejecuciÃ³n en JSON y TXT
- **`scripts_evaluacion/`**
  - `doble_modelo_correccion.py` â­ - Sistema de doble modelo (generador + validador)
  - `validator.py` - ValidaciÃ³n de planes PDDL
  - `get_goal_from_csv.py` - ExtracciÃ³n de goals desde CSV
  - `plan_pruebas.py` - Suite de pruebas automatizadas
  - `cuadros.ipynb` - Notebook de anÃ¡lisis de datos de cuadros

#### `pddl/`
Definiciones PDDL del dominio y problema
- **`domain.pddl`** - Dominio PDDL del robot guÃ­a (acciones, predicados, funciones)
- **`problem.pddl`** - Problema PDDL con estado inicial y objetivos

#### `scripts/`
Scripts auxiliares de utilidad
- `create_explain_files.py` - Genera explicaciones de cuadros usando LLMs
- `split_log_gpt.py` - Procesa y divide logs de GPT
- `trim_plans.py` - Limpia y formatea planes PDDL
- `validate.bash` - Script de validaciÃ³n de planes (requiere VAL validator)
- `run_chat_10_times.sh` - Script de pruebas repetitivas
- `re_practice.py` - Experimentos con expresiones regulares

### ğŸ“ Archivos de Logs (Experimentales)
- `log.txt`, `log.json`, `log_gpt.txt` - Logs de ejecuciones de pruebas
- `logs_script.txt`, `logs_script_deepseek_razonamiento.txt` - Logs de scripts especÃ­ficos
- `colclusiones.md` - Documento con conclusiones del TFG

## ğŸš€ Uso RÃ¡pido

### Generar un plan con LangChain (Gemini/GPT)
```bash
python tfg_langchain/get_plan.py "Explica los cuadros espaÃ±oles"
```

### Generar un plan con Ollama
```bash
python tfg_ollama/create_plan.py "visited monalisa y explicar guernica"
```

### Analizar resultados
```bash
# AnÃ¡lisis simple
python analisis_experimentos.py

# AnÃ¡lisis con mÃ©tricas de planner/validator
python analisis_experimentos_v2.py
```

## ğŸ“Š Modelos Evaluados

- **OpenAI**: GPT-4o, GPT-4o-mini, GPT-o1-mini
- **Google**: Gemini 2.5 Pro, Gemini 2.5 Flash
- **Deepseek**: Deepseek-chat, Deepseek-r1
- **Meta**: Llama 3.x, Llama 4 Maverick
- **Groq**: Varios modelos optimizados para inferencia
- **Minimax**: M2 (MoE 230B/10B con razonamiento)
- **Otros**: Qwen, Mistral, Phi, etc.

## ğŸ”‘ Prompts Principales

Ver `prompts.py` para los prompts completos:
- `prompt_inicial_sin_ejemplos` - GeneraciÃ³n de planes (sin ejemplos)
- `prompt_con_3_ejemplos_input_goal` - GeneraciÃ³n con few-shot learning
- `validate_plan_prompt` - ValidaciÃ³n de planes en formato CSV
- `prompt_get_goal_con_csv` - ExtracciÃ³n de goals con consulta a base de datos

## ğŸ“¦ Dependencias

```bash
pip install -e .
```

Requiere: langchain, langgraph, ollama, pandas, google-genai, groq, openai